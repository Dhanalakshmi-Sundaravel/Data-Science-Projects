{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample code for Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic SVM code  for wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 13) (45, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, random_state=0)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3910056071330086"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "svm = SVC()\n",
    "np.mean(cross_val_score(svm, X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5111111111111111"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train, y_train)\n",
    "svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is very low, and the estimate of accuracy produced by cross-validation is a gross underestimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.9774436090225563\n",
      "Test set score: 0.9777777777777777\n",
      "Best parameters: {'svc__C': 1, 'svc__gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# In the following code I have tried different normalizers\n",
    "# (StandardScaler, MinMaxScaler, RobustScaler, Normalizer)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = make_pipeline(StandardScaler(), SVC())\n",
    "param_grid = {'svc__C': [0.01, 0.1, 1, 10, 100], 'svc__gamma': [0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation accuracy:\", grid.best_score_)\n",
    "print(\"Test set score:\", grid.score(X_test, y_test))\n",
    "print(\"Best parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any of the three scalers and parameter selection improve the results drastically (98% for StandardScaler).  The normalizer gives results that are much worse but not hopeless (score of 91%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-conformal predictor for wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we split the indices of the training set into 3 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(shuffle=True, random_state=0, n_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let now compute the p-values, as in Chapter 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = X_train.shape[0]  # size of the test set\n",
    "n_test = X_test.shape[0]  # size of the test set\n",
    "n_classes = 3  # number of classes\n",
    "p = np.zeros((n_test, n_classes))  # initializing the array of p-values\n",
    "ranks = np.zeros((n_test, n_classes))  # initializing the array for accumulating ranks\n",
    "for rest_index, fold_index in kf.split(X_train):\n",
    "  X_rest, X_fold = X_train[rest_index], X_train[fold_index]\n",
    "  y_rest, y_fold = y_train[rest_index], y_train[fold_index]\n",
    "  grid.fit(X_rest, y_rest)\n",
    "  df_fold = grid.decision_function(X_fold)\n",
    "  df_test = grid.decision_function(X_test)\n",
    "  n_fold = X_fold.shape[0]   # size of the current fold\n",
    "  alpha_fold = np.zeros(n_fold)  # initializing the conformity scores for the fold\n",
    "  for i in range(n_fold):\n",
    "    alpha_fold[i] = df_fold[i,y_fold[i]]  # conformity score of the ith element of the fold\n",
    "  for j in range(n_test):\n",
    "    for l in range(n_classes):\n",
    "      ranks[j,l] = ranks[j,l] + np.sum(alpha_fold <= df_test[j,l])\n",
    "# turning accumulated ranks into p-values:\n",
    "p = (ranks+1) / (n_train+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us use the code given in Lab Worksheet 9 for plotting the calibration curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x231764ba6d8>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "eps = np.zeros(100) # a range of significance levels\n",
    "err = np.zeros(100) # the corresponding error rates\n",
    "for k in range(100):\n",
    "  eps[k] = k/100 # considering eps = k%\n",
    "  err[k] = 0 # initializing the error rate\n",
    "  for j in range(n_test):\n",
    "    if (p[j,y_test[j]] <= eps[k]): # if we made an error\n",
    "      err[k] = err[k] + 1 # count this error\n",
    "  err[k] = err[k] / n_test # number of errors -> error rate\n",
    "plt.plot(eps, err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find the average false p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013930348258706458\n"
     ]
    }
   ],
   "source": [
    "sum_p_values = 0\n",
    "for j in range(n_test):\n",
    "  sum_p_values = sum_p_values + p[j,0] + p[j,1] + p[j,2] - p[j,y_test[j]]\n",
    "print(sum_p_values / (n_test*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net code  for wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3527514783834298"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "np.mean(cross_val_score(mlp, X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35555555555555557"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train, y_train)\n",
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see what the default parameters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is even worse than it was for SVM, but the estimate of accuracy produced by cross-validation is OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.7969924812030075\n",
      "Test set score: 0.9555555555555556\n",
      "Best parameters: {'mlpclassifier__hidden_layer_sizes': (10,), 'mlpclassifier__learning_rate_init': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# In the following code I have tried different normalizers\n",
    "# (StandardScaler, MinMaxScaler, RobustScaler, Normalizer)\n",
    "pipe = make_pipeline(Normalizer(), MLPClassifier())\n",
    "param_grid = {'mlpclassifier__learning_rate_init': [0.001, 0.01, 0.1],\n",
    "  'mlpclassifier__hidden_layer_sizes': [(10,), (100,), (10,10)]}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation accuracy:\", grid.best_score_)\n",
    "print(\"Test set score:\", grid.score(X_test, y_test))\n",
    "print(\"Best parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any of the three scalers and parameter selection improve the results drastically (96% for StandardScaler, slightly worse than for SVM).  It's interesting that the normalizer also gives a good result (score of 96%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic SVM code  for USPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_data = np.genfromtxt(\"zip.train.gz\", usecols=np.arange(1,257), dtype='float')\n",
    "original_test_data = np.genfromtxt(\"zip.test.gz\", usecols=np.arange(1,257), dtype='float')\n",
    "original_data = np.row_stack((original_train_data, original_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_target = np.genfromtxt(\"zip.train.gz\", usecols=0, dtype='int')\n",
    "original_test_target = np.genfromtxt(\"zip.test.gz\", usecols=0, dtype='int')\n",
    "original_target = np.append(original_train_target, original_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9298,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6973, 256) (2325, 256)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(original_data, original_target, random_state=100)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9663001483442297\n",
      "18.09667944908142 seconds\n"
     ]
    }
   ],
   "source": [
    "# In addition to what I did for the wine dataset, I will time the classifier.\n",
    "import time\n",
    "start = time.time()\n",
    "print(np.mean(cross_val_score(svm, X_train, y_train)))\n",
    "print(time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9638709677419355\n",
      "11.90822982788086 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "svm.fit(X_train, y_train)\n",
    "print(svm.score(X_test, y_test))\n",
    "print(time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy appears quite good (perhaps because the digits are already normalized), and the estimate of accuracy produced by cross-validation is also good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.9297289545389359\n",
      "Test set score: 0.9341935483870968\n",
      "Best parameters: {'svc__C': 10, 'svc__gamma': 0.01}\n",
      "520.7920281887054 seconds\n"
     ]
    }
   ],
   "source": [
    "# In the following code I have tried different scalers\n",
    "# (StandardScaler, MinMaxScaler, RobustScaler).\n",
    "# The default value of gamma is 1 / n_features = 1/256.\n",
    "# The default value of C is 1.\n",
    "# For a param_grid of size 4, about 9 minutes (although it might become slower for larger C).\n",
    "# Since the code runs so slowly now I will remember different grids (giving them different names)\n",
    "#   so that I can reuse them easily.\n",
    "import time\n",
    "start = time.time()\n",
    "pipe = make_pipeline(StandardScaler(), SVC())\n",
    "param_grid = {'svc__C': [1, 10], 'svc__gamma': [0.01, 0.1]}\n",
    "grid_s_svc = GridSearchCV(pipe, param_grid=param_grid)\n",
    "grid_s_svc.fit(X_train, y_train)\n",
    "print(\"Best cross-validation accuracy:\", grid_s_svc.best_score_)\n",
    "print(\"Test set score:\", grid_s_svc.score(X_test, y_test))\n",
    "print(\"Best parameters:\", grid_s_svc.best_params_)\n",
    "print(time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.959414885988814\n",
      "Test set score: 0.9539784946236559\n",
      "Best parameters: {'svc__C': 10, 'svc__gamma': 0.1}\n",
      "286.6835927963257 seconds\n"
     ]
    }
   ],
   "source": [
    "# This is identical to the previous cell, except that now we use Normalizer.\n",
    "# For a param_grid of size 4, about 5 minutes.\n",
    "import time\n",
    "start = time.time()\n",
    "pipe = make_pipeline(Normalizer(), SVC())\n",
    "param_grid = {'svc__C': [1, 10], 'svc__gamma': [0.01, 0.1]}\n",
    "grid_n_svc = GridSearchCV(pipe, param_grid=param_grid)\n",
    "grid_n_svc.fit(X_train, y_train)\n",
    "print(\"Best cross-validation accuracy:\", grid_n_svc.best_score_)\n",
    "print(\"Test set score:\", grid_n_svc.score(X_test, y_test))\n",
    "print(\"Best parameters:\", grid_n_svc.best_params_)\n",
    "print(time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalizer and parameter selection do not improve the results.  The three scalers make results worse but surprisingly they do not become hopeless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-conformal predictor for USPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we compute the p-values, as in Chapter 9.  We can use either one of the grids or svm (which as we know works fine, even without preprocessing and with the default values of parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433.49270725250244 seconds\n"
     ]
    }
   ],
   "source": [
    "# About 7 minutes.\n",
    "import time\n",
    "start = time.time()\n",
    "n_train = X_train.shape[0]  # size of the test set\n",
    "n_test = X_test.shape[0]  # size of the test set\n",
    "n_classes = 10  # number of classes\n",
    "p = np.zeros((n_test, n_classes))  # initializing the array of p-values\n",
    "ranks = np.zeros((n_test, n_classes))  # initializing the array for accumulating ranks\n",
    "for rest_index, fold_index in kf.split(X_train):\n",
    "  X_rest, X_fold = X_train[rest_index], X_train[fold_index]\n",
    "  y_rest, y_fold = y_train[rest_index], y_train[fold_index]\n",
    "  grid_n_svc.fit(X_rest, y_rest)\n",
    "  df_fold = grid_n_svc.decision_function(X_fold)\n",
    "  df_test = grid_n_svc.decision_function(X_test)\n",
    "  n_fold = X_fold.shape[0]   # size of the current fold\n",
    "  alpha_fold = np.zeros(n_fold)  # initializing the conformity scores for the fold\n",
    "  for i in range(n_fold):\n",
    "    alpha_fold[i] = df_fold[i,y_fold[i]]  # conformity score of the ith element of the fold\n",
    "  for j in range(n_test):\n",
    "    for l in range(n_classes):\n",
    "      ranks[j,l] = ranks[j,l] + np.sum(alpha_fold <= df_test[j,l])\n",
    "# turning accumulated ranks into p-values:\n",
    "p = (ranks+1) / (n_train+1)\n",
    "print(time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us use the code given in Lab Worksheet 9 for plotting the calibration curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "eps = np.zeros(100) # a range of significance levels\n",
    "err = np.zeros(100) # the corresponding error rates\n",
    "for k in range(100):\n",
    "  eps[k] = k/100 # considering eps = k%\n",
    "  err[k] = 0 # initializing the error rate\n",
    "  for j in range(n_test):\n",
    "    if (p[j,y_test[j]] <= eps[k]): # if we made an error\n",
    "      err[k] = err[k] + 1 # count this error\n",
    "  err[k] = err[k] / n_test # number of errors -> error rate\n",
    "plt.plot(eps, err)\n",
    "plt.xlabel('$\\epsilon$')\n",
    "plt.ylabel('error_rate($\\epsilon$)')\n",
    "plt.gcf().savefig('09_cal_curve.jpg',format='jpg',dpi=300)  # saving for Chapter 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find the average false p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007790540663238938\n"
     ]
    }
   ],
   "source": [
    "sum_p_values = 0\n",
    "for j in range(n_test):\n",
    "  sum_p_values = sum_p_values + p[j,0] + p[j,1] + p[j,2] + p[j,3] + p[j,4] + p[j,5] + p[j,6] + p[j,7] + p[j,8] + p[j,9]  - p[j,y_test[j]]\n",
    "print(sum_p_values / (n_test*9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net code  for USPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9630046265373565\n",
      "19.171876430511475 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "mlp = MLPClassifier()\n",
    "print(np.mean(cross_val_score(mlp, X_train, y_train)))\n",
    "print(time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9655913978494624\n",
      "8.514398336410522 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "mlp.fit(X_train, y_train)\n",
    "print(mlp.score(X_test, y_test))\n",
    "print(time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is good (close to what we get for SVM), and the estimate of accuracy produced by cross-validation is also good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.9675892729097949\n",
      "Test set score: 0.9647311827956989\n",
      "Best parameters: {'mlpclassifier__hidden_layer_sizes': (100,), 'mlpclassifier__learning_rate_init': 0.01}\n",
      "172.5464310646057 seconds\n"
     ]
    }
   ],
   "source": [
    "# In the following code I have tried different scalers\n",
    "# (StandardScaler, MinMaxScaler, RobustScaler).\n",
    "# About 2 minutes.\n",
    "import time\n",
    "start = time.time()\n",
    "pipe = make_pipeline(StandardScaler(), MLPClassifier())\n",
    "param_grid = {'mlpclassifier__learning_rate_init': [0.001, 0.01, 0.1],\n",
    "  'mlpclassifier__hidden_layer_sizes': [(10,), (100,), (10,10)]}\n",
    "grid_s_mlp = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
    "grid_s_mlp.fit(X_train, y_train)\n",
    "print(\"Best cross-validation accuracy:\", grid_s_mlp.best_score_)\n",
    "print(\"Test set score:\", grid_s_mlp.score(X_test, y_test))\n",
    "print(\"Best parameters:\", grid_s_mlp.best_params_)\n",
    "print(time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\uhac013\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.9638606051914528\n",
      "Test set score: 0.9643010752688173\n",
      "Best parameters: {'mlpclassifier__hidden_layer_sizes': (100,), 'mlpclassifier__learning_rate_init': 0.01}\n",
      "268.43754267692566 seconds\n"
     ]
    }
   ],
   "source": [
    "# This is identical to the previous cell except that now Normalizer is used.\n",
    "# About 2 minutes.\n",
    "import time\n",
    "start = time.time()\n",
    "pipe = make_pipeline(Normalizer(), MLPClassifier())\n",
    "param_grid = {'mlpclassifier__learning_rate_init': [0.001, 0.01, 0.1],\n",
    "  'mlpclassifier__hidden_layer_sizes': [(10,), (100,), (10,10)]}\n",
    "grid_n_mlp = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
    "grid_n_mlp.fit(X_train, y_train)\n",
    "print(\"Best cross-validation accuracy:\", grid_n_mlp.best_score_)\n",
    "print(\"Test set score:\", grid_n_mlp.score(X_test, y_test))\n",
    "print(\"Best parameters:\", grid_n_mlp.best_params_)\n",
    "print(time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default values of parameters are OK, and parameter selection does not improve the results. Normalizer works fine (although it does not improve the results), and the scalers do not make the results substantially worse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
